================================================================================
SCALING GUIDE: Handling 1000+ Concurrent Requests
================================================================================

OVERVIEW
--------
Your system now supports both vertical and horizontal scaling to handle
1000+ concurrent requests with automatic scaling based on load.


VERTICAL SCALING (Bigger Instances)
------------------------------------
✅ ECS Tasks: 256 CPU → 1024 CPU (4x increase)
✅ ECS Memory: 512 MB → 2048 MB (4x increase)
✅ Workers: 1 → 4 Uvicorn workers per task
✅ RDS: db.t3.micro → db.t3.medium
✅ Storage: 20GB → 100GB with auto-scaling to 200GB
✅ IOPS: Standard → 3000 provisioned IOPS


HORIZONTAL SCALING (More Instances)
------------------------------------
✅ Min Tasks: 1 → 3 (high availability)
✅ Max Tasks: 10 → 20 (2x capacity)
✅ Scale-out: 60s cooldown (fast response)
✅ Scale-in: 180s cooldown (prevent flapping)
✅ Read Replica: Added for database load distribution


SCALING TRIGGERS
----------------
1. CPU-Based: Scales at 60% CPU (aggressive)
2. Request-Based: Scales at 500 requests/min per task
3. Memory-Based: Scales at 80% memory
4. Step Scaling: Emergency scaling at 85% CPU


CAPACITY CALCULATION
--------------------
Per Task:
- 1 vCPU, 2GB RAM, 4 workers
- ~1000 concurrent requests per task
- ~50 requests/second per task

Total Capacity (20 tasks):
- 20 vCPUs, 40GB RAM, 80 workers
- ~20,000 concurrent requests
- ~1000 requests/second


DEPLOYMENT
----------
# Deploy high-load configuration
cd sensor-backend/terraform
terraform apply -target=aws_ecs_task_definition.app_task_high_performance
terraform apply -target=aws_appautoscaling_target.ecs_target_high_load
terraform apply -target=aws_db_instance.postgres_high_performance

# Or deploy everything
terraform apply


TESTING
-------
# Test with 1000 concurrent requests
python3 test_1000_concurrent.py

# Monitor scaling in real-time
python3 scripts/monitor_dashboard.py

# Watch ECS tasks scale
aws ecs describe-services \
  --cluster sensor-app-cluster \
  --services sensor-app-service \
  --region us-east-2


MONITORING SCALING
------------------
# Check current task count
aws ecs describe-services \
  --cluster sensor-app-cluster \
  --services sensor-app-service \
  --query 'services[0].[runningCount,desiredCount]' \
  --region us-east-2

# Check CPU utilization
aws cloudwatch get-metric-statistics \
  --namespace AWS/ECS \
  --metric-name CPUUtilization \
  --dimensions Name=ClusterName,Value=sensor-app-cluster \
  --start-time $(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 60 \
  --statistics Average \
  --region us-east-2


SCALING TIMELINE (Under Load)
------------------------------
Time    | Load      | Tasks | Action
--------|-----------|-------|----------------------------------
0:00    | 0 req/s   | 3     | Baseline (min capacity)
0:30    | 500 req/s | 3     | Normal operation
1:00    | 1000 req/s| 5     | CPU hits 60%, scale-out triggered
1:30    | 1500 req/s| 8     | Request-based scaling kicks in
2:00    | 2000 req/s| 12    | Continued scaling
3:00    | 3000 req/s| 18    | Near max capacity
3:30    | 3500 req/s| 20    | Max capacity reached
4:00    | 2000 req/s| 20    | Cooldown period
5:00    | 1000 req/s| 12    | Scale-in begins
7:00    | 500 req/s | 5     | Returning to normal
10:00   | 100 req/s | 3     | Back to baseline


COST OPTIMIZATION
-----------------
Current Config (Low Load):
- 3 tasks × $0.04/hour = $0.12/hour = $86/month
- RDS db.t3.medium = $0.068/hour = $49/month
Total: ~$135/month

Peak Load (High Traffic):
- 20 tasks × $0.04/hour = $0.80/hour
- Only during high load periods
- Auto-scales down when traffic decreases


PERFORMANCE TUNING
------------------
1. Database Connection Pool:
   - Set MAX_CONNECTIONS=100 per task
   - Total: 2000 connections (20 tasks × 100)
   - RDS max_connections should be 2500+

2. Uvicorn Workers:
   - 4 workers per task
   - Total: 80 workers across all tasks

3. ALB Settings:
   - Connection draining: 30s
   - Sticky sessions: Enabled
   - HTTP/2: Enabled

4. Read Replica:
   - Route read queries to replica
   - Write queries to primary
   - Reduces primary database load by ~60%


TROUBLESHOOTING
---------------
Issue: Tasks not scaling up
Fix: Check CloudWatch alarms, verify IAM permissions

Issue: High latency despite scaling
Fix: Check database performance, add indexes, use read replica

Issue: Tasks scaling too aggressively
Fix: Increase target CPU threshold from 60% to 70%

Issue: Database connection errors
Fix: Increase RDS max_connections parameter

Issue: Tasks at max but still slow
Fix: Increase max_capacity from 20 to 30


MANUAL SCALING (Emergency)
---------------------------
# Force scale to 10 tasks immediately
aws ecs update-service \
  --cluster sensor-app-cluster \
  --service sensor-app-service \
  --desired-count 10 \
  --region us-east-2

# Scale database vertically
aws rds modify-db-instance \
  --db-instance-identifier sensor-postgres-high-perf \
  --db-instance-class db.t3.large \
  --apply-immediately \
  --region us-east-2


BEST PRACTICES
--------------
✅ Always start with min 3 tasks for HA
✅ Set aggressive scale-out (30s) for burst traffic
✅ Set conservative scale-in (180s) to prevent flapping
✅ Monitor request latency, not just CPU
✅ Use read replicas for read-heavy workloads
✅ Enable Performance Insights on RDS
✅ Set up CloudWatch alarms for max capacity
✅ Test scaling with load tests regularly


NEXT STEPS
----------
1. Deploy: terraform apply
2. Test: python3 test_1000_concurrent.py
3. Monitor: python3 scripts/monitor_dashboard.py
4. Tune: Adjust thresholds based on actual traffic
5. Optimize: Add caching, CDN, or API Gateway if needed
